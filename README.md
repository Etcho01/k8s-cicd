# High Availability Kubernetes Cluster on AWS

> **Production-ready Kubernetes v1.30 cluster with 3 control plane nodes, Network Load Balancer, automated node joining, and complete observability stack**
--
## ğŸ¯ Overview

This project provides a complete Infrastructure as Code (IaC) solution for deploying a **production-ready High Availability Kubernetes cluster** on AWS using Terraform. The cluster features:

- **3 Control Plane Nodes** for HA with automatic failover
- **2 Worker Nodes** for workload execution
- **Network Load Balancer** for stable API endpoint
- **Automatic Node Joining** via S3 (no manual intervention)
- **Private Docker Registry** for container images
- **Complete Observability** with Prometheus + Grafana
- **Custom Node Hostnames** (master1-3, worker1-2)

### Why This Solution?

âœ… **Production-Ready**: Follows official Kubernetes HA documentation  
âœ… **Fully Automated**: Zero manual steps after deployment  
âœ… **Complete Monitoring**: Enterprise-grade observability included  
âœ… **Battle-Tested**: Uses Ubuntu 22.04 LTS and stable K8s versions  
âœ… **Infrastructure as Code**: Version-controlled, repeatable deployments  

---

## ğŸ—ï¸ Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AWS Cloud (eu-west-1)                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    VPC (10.0.0.0/16)                        â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚              Network Load Balancer                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚         (Kubernetes API Endpoint)                    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚    k8s-api-nlb-xxx.elb.eu-west-1.amazonaws.com      â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                     â”‚                                      â”‚ â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚ â”‚
â”‚  â”‚         â”‚           â”‚           â”‚              â”‚          â”‚ â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚    â”‚Master1 â”‚  â”‚Master2 â”‚  â”‚Master3 â”‚   â”‚ Worker â”‚     â”‚ â”‚
â”‚  â”‚    â”‚Control â”‚  â”‚Control â”‚  â”‚Control â”‚   â”‚  Nodes â”‚     â”‚ â”‚
â”‚  â”‚    â”‚ Plane  â”‚  â”‚ Plane  â”‚  â”‚ Plane  â”‚   â”‚ (x2)   â”‚     â”‚ â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚         â”‚                                      â”‚          â”‚ â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚ â”‚
â”‚  â”‚                          â”‚                                â”‚ â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚ â”‚
â”‚  â”‚              â”‚   Monitoring Stack    â”‚                   â”‚ â”‚
â”‚  â”‚              â”‚  Prometheus + Grafana â”‚                   â”‚ â”‚
â”‚  â”‚              â”‚    Node Exporters     â”‚                   â”‚ â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚ â”‚
â”‚  â”‚  â”‚  Registry  â”‚         â”‚   S3 Bucket     â”‚            â”‚ â”‚
â”‚  â”‚  â”‚   Server   â”‚         â”‚ (Join Commands) â”‚            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Network Architecture

```
VPC (10.0.0.0/16)
â”œâ”€â”€ Public Subnets (10.0.1.0/24, 10.0.2.0/24)
â”‚   â”œâ”€â”€ Network Load Balancer
â”‚   â”œâ”€â”€ 3 Master Nodes (control plane)
â”‚   â”œâ”€â”€ 2 Worker Nodes (compute)
â”‚   â””â”€â”€ 1 Repository Host (Docker registry)
â”œâ”€â”€ Private Subnets (10.0.10.0/24, 10.0.11.0/24)
â”‚   â””â”€â”€ Reserved for future use
â”œâ”€â”€ Internet Gateway
â””â”€â”€ S3 Bucket (join commands storage)
```

### Monitoring Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Monitoring Namespace                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Prometheus  â”‚â—„â”€â”€â”€â”€â”€â”¤   Exporters  â”‚                    â”‚
â”‚  â”‚   Server     â”‚      â”‚              â”‚                    â”‚
â”‚  â”‚  (Metrics    â”‚      â”‚ - Node       â”‚                    â”‚
â”‚  â”‚   Storage)   â”‚      â”‚ - kube-state â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ - cAdvisor   â”‚                    â”‚
â”‚         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚
â”‚  â”‚   Grafana    â”‚ (Visualization)                          â”‚
â”‚  â”‚  Dashboards  â”‚ http://<node-ip>:30300                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚
â”‚                                                              â”‚
â”‚  Monitors: All 5 nodes (masters + workers)                 â”‚
â”‚  Retention: 15 days                                         â”‚
â”‚  Metrics: CPU, Memory, Disk, Network, K8s Objects          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### Core Kubernetes Features
- âœ… **High Availability**: 3 control plane nodes with automatic failover
- âœ… **Network Load Balancer**: Stable endpoint for API server (--control-plane-endpoint)
- âœ… **Automatic Node Joining**: S3-based join command distribution
- âœ… **Custom Hostnames**: Nodes named master1-3, worker1-2 (not IPs)
- âœ… **Flannel CNI**: Pod networking with VXLAN overlay
- âœ… **Ubuntu 22.04 LTS**: Long-term support until 2027
- âœ… **Kubernetes 1.30**: Latest stable release

### Monitoring & Observability
- âœ… **Prometheus**: Metrics collection and storage (15-day retention)
- âœ… **Grafana**: Beautiful dashboards and visualization
- âœ… **Node Exporter**: Hardware metrics (CPU, RAM, disk, network)
- âœ… **kube-state-metrics**: Kubernetes object metrics
- âœ… **Pre-configured Dashboards**: Import and use immediately
- âœ… **Automated Installation**: One-script deployment
- âœ… **Real-time Monitoring**: All 5 nodes monitored continuously

### Infrastructure Features
- âœ… **Modular Terraform**: Reusable modules (network, security, ec2, loadbalancer)
- âœ… **S3 State Backend**: Remote state with locking via DynamoDB
- âœ… **Encrypted Storage**: EBS volumes encrypted at rest
- âœ… **IAM Roles**: Instance profiles for secure AWS API access
- âœ… **Security Groups**: Least-privilege network access
- âœ… **Monitoring Ports**: Grafana (30300), Prometheus (30900)
- âœ… **Proper Tagging**: Organized resource management

### Operational Features
- âœ… **Professional Outputs**: Clear SSH commands and cluster info
- âœ… **Private Docker Registry**: Self-hosted container registry
- âœ… **Complete Documentation**: Comprehensive guides and troubleshooting
- âœ… **Automation Scripts**: One-command monitoring installation
- âœ… **Validation Scripts**: Pre-deployment checks

---

## ğŸ“‹ Prerequisites

### Required Tools
- **Terraform** >= 1.7.0 ([Install](https://www.terraform.io/downloads))
- **AWS CLI** v2 ([Install](https://aws.amazon.com/cli/))
- **SSH Client** (ssh command)
- **Git** (for cloning repository)

### AWS Requirements
- **AWS Account** with appropriate permissions
- **IAM Permissions**:
  - EC2 (instances, VPC, security groups, load balancers)
  - S3 (bucket creation and management)
  - IAM (roles and policies)
  - DynamoDB (for state locking)

### SSH Key Setup
```bash
# Create SSH key pair in AWS (if not exists)
aws ec2 create-key-pair \
  --key-name wsl-terraform-key \
  --region eu-west-1 \
  --query 'KeyMaterial' \
  --output text > wsl-terraform-key.pem

# Set proper permissions
chmod 400 wsl-terraform-key.pem
```

### AWS Credentials
```bash
# Configure AWS CLI
aws configure

# Or export credentials
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_DEFAULT_REGION="eu-west-1"
```

---

## ğŸ“‚ Project Structure

```
k8s-cicd/
â”œâ”€â”€ main.tf                          # Root orchestration
â”œâ”€â”€ variables.tf                     # Input variables
â”œâ”€â”€ outputs.tf                       # Formatted outputs
â”œâ”€â”€ provider.tf                      # AWS provider config
â”œâ”€â”€ terraform.tf                     # Backend configuration
â”œâ”€â”€ terraform.tfvars.example         # Example variables
â”œâ”€â”€ wsl-terraform-key.pem           # Your SSH key
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ master_setup.sh              # First master initialization
â”‚   â”œâ”€â”€ master_join.sh               # Additional masters join
â”‚   â”œâ”€â”€ worker_setup.sh              # Workers join
â”‚   â”œâ”€â”€ repo_setup.sh                # Docker registry setup
â”‚   â”œâ”€â”€ install-monitoring.sh        # Monitoring automation (NEW)
â”‚   â””â”€â”€ setup-terraform-backend.sh   # S3/DynamoDB creation
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ network/                     # VPC, subnets, routing
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â”œâ”€â”€ securitygroups/              # Security groups
â”‚   â”‚   â”œâ”€â”€ main.tf                  # (Updated with monitoring ports)
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â”œâ”€â”€ loadbalancer/                # Network Load Balancer
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”‚
â”‚   â””â”€â”€ ec2/                         # EC2 instances + IAM
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ outputs.tf
â”‚
â””â”€â”€ docs/                            # Additional documentation
    â”œâ”€â”€ PROMETHEUS-SETUP.md          # Detailed monitoring guide
    â”œâ”€â”€ MONITORING-COMMANDS.md       # Monitoring cheat sheet
    â””â”€â”€ TROUBLESHOOTING.md          # Common issues and fixes
```

---

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone <your-repo-url>
cd k8s-cicd
```

### 2. Setup Backend
```bash
# Create S3 bucket and DynamoDB table for state management
chmod +x scripts/setup-terraform-backend.sh
./scripts/setup-terraform-backend.sh

# Note the bucket name from output
# Update terraform.tf with your bucket name
```

### 3. Configure Variables
```bash
# Copy example configuration
cp terraform.tfvars.example terraform.tfvars

# Edit with your values
vim terraform.tfvars
```

**Required Changes:**
```hcl
admin_cidr      = "YOUR_PUBLIC_IP/32"  # Get: curl ifconfig.me
monitoring_cidr = "YOUR_PUBLIC_IP/32"  # For Grafana/Prometheus access
```

### 4. Deploy Infrastructure
```bash
# Initialize Terraform
terraform init

# Validate configuration
terraform validate

# Preview changes
terraform plan

# Deploy infrastructure (takes ~15 minutes)
terraform apply
```

### 5. Wait for Cluster Initialization
```bash
# The cluster takes ~15 minutes to fully initialize
# - Minutes 0-2:   Infrastructure creation
# - Minutes 2-10:  Master1 initializes Kubernetes
# - Minutes 10-13: Masters 2-3 join cluster
# - Minutes 13-15: Workers 1-2 join cluster

# Check progress
ssh -i wsl-terraform-key.pem ubuntu@$(terraform output -json master_nodes | jq -r '.[0].public_ip')
kubectl get nodes
```

### 6. Install Monitoring Stack
```bash
# Still on master1, download and run monitoring installer
curl -fsSL https://raw.githubusercontent.com/YOUR_REPO/main/scripts/install-monitoring.sh -o install-monitoring.sh
chmod +x install-monitoring.sh
./install-monitoring.sh

# Or if you have the file locally
./scripts/install-monitoring.sh

# Wait 2-3 minutes for installation
```

### 7. Access Grafana
```bash
# Get node IP from installer output or run:
kubectl get nodes -o wide

# Open browser: http://<node-ip>:30300
# Login: admin / admin123
```

### 8. Import Dashboards
In Grafana:
1. Click **â˜°** â†’ **Dashboards** â†’ **Import**
2. Enter dashboard ID: **1860** (Node Exporter Full)
3. Click **Load** â†’ **Import**
4. Repeat for IDs: **15760**, **14623**

**ğŸ‰ Your cluster with complete monitoring is ready!**

---

## ğŸ“Š Monitoring Stack

### What Gets Installed

The monitoring stack includes:

| Component | Purpose | Port | Access |
|-----------|---------|------|--------|
| **Prometheus** | Metrics collection and storage | 30900 | http://node-ip:30900 |
| **Grafana** | Visualization and dashboards | 30300 | http://node-ip:30300 |
| **Node Exporter** | Hardware metrics (5 pods, 1 per node) | 9100 | Internal only |
| **kube-state-metrics** | Kubernetes object metrics | 8080 | Internal only |
| **Alertmanager** | Alert management | 9093 | Internal only |

### Key Metrics Monitored

**Per-Node Metrics:**
- CPU usage (per core and total)
- Memory usage (used, free, cached, buffers)
- Disk I/O (IOPS, throughput, latency)
- Network traffic (bandwidth, packets, errors)
- Disk space usage
- System load averages
- Process counts

**Cluster-Wide Metrics:**
- Total pods running
- Pods per namespace
- Resource usage by namespace
- Failed/Pending pods
- Container restarts
- API server performance
- etcd performance

### Automated Installation

The `install-monitoring.sh` script automates everything:

```bash
# What it does:
âœ“ Checks cluster health
âœ“ Installs Helm if needed
âœ“ Adds Prometheus repository
âœ“ Creates monitoring namespace
âœ“ Generates optimized configuration (reduced memory for t3.small)
âœ“ Installs Prometheus + Grafana + exporters
âœ“ Waits for pods to be ready
âœ“ Displays access information

# Optimized for your cluster:
- Memory: 512Mi request, 1Gi limit (fits t3.small instances)
- Storage: emptyDir (no PVC needed)
- Monitoring: All 5 nodes (masters + workers)
- Retention: 15 days of metrics
```

### Recommended Dashboards

| ID | Name | What It Shows |
|----|------|---------------|
| **1860** | Node Exporter Full | Detailed hardware metrics per node |
| **15760** | Kubernetes Cluster | Cluster-wide overview and health |
| **14623** | Kubernetes Pod Resources | Pod-level CPU, memory, network |

### Quick Access

```bash
# Check monitoring pods
kubectl get pods -n monitoring

# View Grafana logs
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana

# Check Prometheus targets
# Open: http://<node-ip>:30900/targets

# Restart Grafana (if needed)
kubectl rollout restart deployment/prometheus-grafana -n monitoring
```

---

## âš™ï¸ Configuration

### Key Variables (terraform.tfvars)

```hcl
# AWS Configuration
aws_region  = "eu-west-1"
environment = "dev"
owner       = "your-name"

# Network Configuration
vpc_cidr             = "10.0.0.0/16"
public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24"]
private_subnet_cidrs = ["10.0.10.0/24", "10.0.11.0/24"]

# Cluster Configuration
master_count = 3
worker_count = 2

# Instance Configuration
instance_type    = "t3.small"       # 2 vCPU, 2GB RAM
root_volume_size = 20               # GB
root_volume_type = "gp3"

# Security
key_name        = "wsl-terraform-key"
admin_cidr      = "YOUR_IP/32"      # For SSH and K8s API
monitoring_cidr = "YOUR_IP/32"      # For Grafana/Prometheus
```

### Security Group Ports

The following ports are automatically configured:

**Kubernetes Cluster:**
- 6443 (API Server)
- 2379-2380 (etcd)
- 10250 (Kubelet)
- 10257 (Controller Manager)
- 10259 (Scheduler)
- 8472 (Flannel VXLAN)
- 30000-32767 (NodePort services)

**Monitoring Stack:**
- 30300 (Grafana UI) - from your IP only
- 30900 (Prometheus UI) - from your IP only
- 9100 (Node Exporter) - internal only
- 9090 (Prometheus) - internal only
- 8080 (kube-state-metrics) - internal only

**Docker Registry:**
- 5000 (Registry HTTPS) - from cluster nodes only

---

## ğŸ¯ Deployment

### Full Deployment Timeline

| Time | Phase | What's Happening |
|------|-------|------------------|
| 0-2 min | Infrastructure | VPC, subnets, NLB, S3, security groups |
| 2-10 min | Master1 | Kubernetes initialization, join commands to S3 |
| 10-13 min | Masters 2-3 | Join cluster as control plane nodes |
| 13-15 min | Workers 1-2 | Join cluster as worker nodes |
| 15+ min | Monitoring | Install Prometheus + Grafana (2-3 min) |

### Deployment Outputs

After `terraform apply`, you'll see:

```
Outputs:

deployment_summary = <<EOT

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  KUBERNETES CLUSTER DEPLOYMENT SUMMARY                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ CLUSTER INFORMATION
â”œâ”€ Kubernetes Version: v1.30.0
â”œâ”€ Control Plane Endpoint: k8s-api-nlb-xxx.elb.eu-west-1.amazonaws.com:6443
â”œâ”€ CNI Plugin: Flannel
â”œâ”€ Pod Network: 10.244.0.0/16
â””â”€ Nodes: 3 masters, 2 workers

ğŸ–¥ï¸  MASTER NODES
â”œâ”€ master1: 54.194.123.45 (10.0.1.10)
â”œâ”€ master2: 54.194.123.46 (10.0.1.20)
â””â”€ master3: 54.194.123.47 (10.0.1.30)

ğŸ‘· WORKER NODES
â”œâ”€ worker1: 54.194.123.48 (10.0.2.10)
â””â”€ worker2: 54.194.123.49 (10.0.2.20)

ğŸ“¦ REPOSITORY HOST
â””â”€ repo: 54.194.123.50 (Docker Registry: http://10.0.1.50:5000)

ğŸ“š NEXT STEPS
1. Wait ~15 minutes for cluster initialization
2. SSH to master1: ssh -i wsl-terraform-key.pem ubuntu@54.194.123.45
3. Verify cluster: kubectl get nodes
4. Install monitoring: ./install-monitoring.sh
5. Access Grafana: http://54.194.123.45:30300

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOT
```

---

## ğŸ” Post-Deployment

### Verify Cluster

```bash
# SSH to master1
ssh -i wsl-terraform-key.pem ubuntu@<MASTER1_IP>

# Check nodes (should all be Ready)
kubectl get nodes

# Check system pods (should all be Running)
kubectl get pods -A

# Check cluster info
kubectl cluster-info
```

### Install Monitoring

```bash
# Download and run installer
curl -fsSL https://raw.githubusercontent.com/YOUR_REPO/main/scripts/install-monitoring.sh -o install-monitoring.sh
chmod +x install-monitoring.sh
./install-monitoring.sh

# Or if file is local
./scripts/install-monitoring.sh

# Wait 2-3 minutes for installation
```

### Access Monitoring

```bash
# Get node IP
kubectl get nodes -o wide

# Access in browser:
# Grafana:    http://<node-ip>:30300 (admin/admin123)
# Prometheus: http://<node-ip>:30900

# Import dashboards
# IDs: 1860, 15760, 14623

# Destroy cluster
terraform destroy
```

---

## ğŸš€ Getting Started Checklist

Before you begin, make sure you have:

- [ ] AWS account with appropriate permissions
- [ ] AWS CLI configured (`aws configure`)
- [ ] Terraform installed (>= 1.7.0)
- [ ] SSH key created in AWS
- [ ] Your public IP noted (`curl ifconfig.me`)
- [ ] Git repository cloned

**Deployment Steps:**

1. [ ] Setup Terraform backend (`./scripts/setup-terraform-backend.sh`)
2. [ ] Configure `terraform.tfvars` with your IP
3. [ ] Run `terraform init`
4. [ ] Run `terraform apply`
5. [ ] Wait ~15 minutes for cluster initialization
6. [ ] SSH to master1 and verify cluster (`kubectl get nodes`)
7. [ ] Run `./install-monitoring.sh` on master1
8. [ ] Access Grafana at `http://<node-ip>:30300`
9. [ ] Import dashboards (1860, 15760, 14623)
10. [ ] Start deploying your applications!

---

## ğŸ‘¤ Author

**Mohamed Hesham**
- Project: cicd-k8s
- Environment: dev

---


## ğŸ“Š Project Status

**Status:** âœ… **Production Ready**  
**Last Updated:** November 2025  
**Terraform Version:** >= 1.7.0  
**Kubernetes Version:** v1.30.0  
**OS:** Ubuntu 22.04 LTS

---